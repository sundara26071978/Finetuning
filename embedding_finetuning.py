# -*- coding: utf-8 -*-
"""Embedding_Finetuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZuhuyUkg9TfwCQ_dq-FyFxNxRZvKWdrX

# Practical Guide to Fine-tuning Embedding Models for RAG Systems

## Load datasets
"""

from datasets import load_dataset
dataset= load_dataset("dipanjanS/india_rag_wikidata", split="train")

dataset

import pandas as pd
df=pd.DataFrame(dataset)
df.head(3)

data_df=df[['question','context']]
data_df.head(3)

df_train =data_df.reset_index(drop=True)
df_eval=df_train.sample(100).reset_index(drop=True)

df_train.shape, df_eval.shape

from datasets import Dataset
train_dataset = Dataset.from_pandas(df_train)
eval_dataset = Dataset.from_pandas(df_eval)

"""## Step 2 - Load Pre-Trained Embedding Model"""

from sentence_transformers import SentenceTransformer
model = SentenceTransformer("BAAI/bge-base-en-v1.5")
model

"""## Step 2 - Choose Loss Function

"""

from sentence_transformers.losses import MultipleNegativesRankingLoss
loss = MultipleNegativesRankingLoss(model)
loss

"""## Step 3 - Setup Training Arguments"""

from sentence_transformers import SentenceTransformerTrainingArguments
from sentence_transformers.training_args import BatchSamplers
args = SentenceTransformerTrainingArguments(
    output_dir="bge-base-runs",
    max_steps=332,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    evaluation_strategy="steps",
    save_strategy="steps",
    eval_steps=20,
    save_steps=100,
    save_total_limit=2,
    warmup_steps=1,
    learning_rate=3e-6,
    warmup_ratio=0.1,
    weight_decay=0.03,
    logging_steps=10,
    fp16=True,
    bf16=False,
    batch_sampler=BatchSamplers.NO_DUPLICATES,

)

"""## Step 4 - Setup Trainer & Fine-tune Embedding Model"""

from sentence_transformers import SentenceTransformerTrainer
trainer = SentenceTransformerTrainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    loss=loss
)

trainer.train()

model.save_pretrained("sunj-bge-base-en-v1.5")

import shutil

# Model folder ka naam jo tu save kar chuka hai
model_folder = "/content/sunj-bge-base-en-v1.5"

# Model ko zip me convert karo
shutil.make_archive("sunj-bge-base-en-v1.5", 'zip', model_folder)

print("Model successfully zipped as sunj-bge-base-en-v1.5.zip")

from huggingface_hub import notebook_login

notebook_login()

from transformers import AutoModelForTokenClassification, AutoTokenizer
from huggingface_hub import HfApi

# Model directory (jisme fine-tuned model hai)
model_dir = "/content/sunj-bge-base-en-v1.5"

model_fine_tuned=SentenceTransformer(model_dir)

# Push model to Hugging Face
model_fine_tuned.push_to_hub("sunjupskilling/sunj-bge-base-en-v1.5")

